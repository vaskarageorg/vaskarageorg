#28 / 1/ 2020 : UPDATE

# Let's work on this as reference.

# What I've done is in the headers. Basically, it's imputation, univariate regression with correction for metabolomics.

#24 / 1/ 2020 : UPDATE. 
#This is the code with some stuff for preprocessing.

#We will go thorugh the first Aim (Univariate analyses)

#Rebecca: Protein + Covars

#Tarana: Adductomics + Covars

#Vasilis: Metabolomics + Covars

# Metabolome Script

# Load Files, Missingness Investigation----
covar <- readRDS('Covariates.rds')

#Relevelling Gel Status so that NA is a value. OK's are '1', Gel's are '2', NA's are 'Missing'
covar$Gel.status = ifelse(is.na(covar$Gel.status), 'Missing', covar$Gel.status)

mtb = read.csv("/rdsgpfs/general/project/hda_tds/live/Mechanomics/Metabolites/Lung cancer feature table RP NEG_231019.csv")

mtb.by.participant = t(as.matrix(mtb))


#We fix the ID's of participants in mtb and covar datasets so that we can later join the two sets.
library(stringr)

rowmetabol <- rownames(mtb.by.participant)
rowmetabol.clean <- gsub("_1$",".1",rowmetabol)
rowmetabol.clean <- gsub("_2$",".2",rowmetabol.clean)
rowmetabol.fin <- gsub(".*_","",rowmetabol.clean)
rownames(mtb.by.participant) <- rowmetabol.fin

# Excluding 17 blanks in the mtb.by.paricipant dataset
mtb.by.part = mtb.by.participant[18:667,]

names.covariates = sort(as.numeric(rownames(covar)))
names.metabol = sort(as.numeric(rownames(mtb.by.part)))
(names.covariates == names.metabol)
#THere is a discrepancy at position [295]. Namely, there is an extra ID of 2103767 in metabol dataset
names.covariates[295]
names.metabol[295]

#We look further to find the other discrepancy
names.covariates.plus295 = names.covariates[295:648]
names.metabol.plus295 = names.metabol[296:650]
names.covariates.plus295 == names.metabol.plus295

# One More in position 47
names.covariates.plus295[48]
names.metabol.plus295[48]

# The extra ID is 2106943. SO, IN THE MTB dataset, there are 2 MEASUREMENTS for 2 ID's,
# Namely: 2106943, 2103767. We can either take the mean or use mixed models. 

# For these 2 observations, to reduce complexity,
# and since it's only 2/650 observations, we'll take the mean wherever there are 2 observations and
# the observed value where one of them is NA

length(mtb.by.part[rownames(mtb.by.part) == 2106943])
length(mtb.by.part[rownames(mtb.by.part) == 2103767])

vector.2106943 = matrix(as.numeric(mtb.by.part[rownames(mtb.by.part) == 2106943,]), byrow = F, nrow = 2)
vector.2106943[1:2, 120:130]

vec1 = as.data.frame(vector.2106943)
vec1.3 = ifelse(is.na(vec1[1,1:4828]) | is.na(vec1[2,1:4828]), 1,0 )
vec.all = rbind(vec1, vec1.3)
vec.all[is.na(vec.all)] <- 0

# Probably not the fastest way but still works. Wherever there is 1 NA, we take the value. WHerevere both
# observations are available, we take the mean. NA's are changed to 0's for facilitating code

mean.or.NA = ifelse(vec.all[3,] == 0, (vec.all[1,] + vec.all[2,])/2, vec.all[,1] +  vec.all[2,])
meanNA2106943 = unlist(mean.or.NA)
meanNA2106943[meanNA2106943 == 0] <- NA
mtb.by.part2 = rbind(mtb.by.part, meanNA2106943)

#Dropping the other rows
drop.index.2106943 = which(rownames(mtb.by.part2) == "2106943")
mtb.by.part2 = mtb.by.part2[-drop.index.2106943,]
dim(mtb.by.part2)

# The same process for ID 2103767. rownames(mtb.by.part2) lathos
vector.2103767 = matrix(as.numeric(mtb.by.part2[rownames(mtb.by.part2) == 2103767,]), byrow = F, nrow = 2)
vector.2103767[1:2, 120:130]

vec1 = as.data.frame(vector.2103767)
vec1.3 = ifelse(is.na(vec1[1,1:4828]) | is.na(vec1[2,1:4828]), 1,0 )
vec.all = rbind(vec1, vec1.3)
vec.all[is.na(vec.all)] <- 0

# Probably not the fastest way but still works. Wherever there is 1 NA, we take the value. WHerevere both
# observations are available, we take the mean. NA's are changed to 0's for facilitating code

mean.or.NA = ifelse(vec.all[3,] == 0, (vec.all[1,] + vec.all[2,])/2, vec.all[,1] +  vec.all[2,])
meanNA2103767 = unlist(mean.or.NA)
meanNA2103767[meanNA2103767 == 0] <- NA
mtb.by.part3 = rbind(mtb.by.part2, meanNA2103767)

#Dropping the other rows
drop.index.2103767 = which(rownames(mtb.by.part3) == "2103767")
mtb.by.part3 = mtb.by.part3[-drop.index.2103767,]
dim(mtb.by.part3)

#648, now they match with covars

# Firstly, we will be excluding those metabolites for whom >70% of the values are missing
mtb.NAs = ifelse(is.na(mtb.by.part3) == T, 1, 0)

na.proportion.vector = apply(mtb.NAs, 1, mean)

hist(na.proportion.vector,breaks = 1000)
# DATA-DRIVEN choice of cut-off: 0.65

mtb.lessthan60 = mtb.by.part3[which(na.proportion.vector < 0.6),]
dim(mtb.lessthan65)
  
# In the remaining dataset, we will be treating missing or not as a binary outcome 
# 
# and run logistic regression as follows: missingness ~ age + gender + BMI + ...
#
# We will accordingly correct for multiple comparisons
linearmod.NAs = function(metabolite.missing){
  mod1 = glm(metabolite.missing ~ covar$age.sample + covar$case + covar$cohort ,
             family = binomial())
  summa = summary(mod1)
  age.pval = summa$coefficients[2,4]
  ccstatus.pval = summa$coefficients[3,4]
  cohort.pval = summa$coefficients[4,4]
  df.pval = data.frame(summa$coefficients[2,4], summa$coefficients[3,4], summa$coefficients[4,4])
  colnames(df.pval) = NULL
  return(df.pval)
  
}

pval = apply(mtb.NAs, 2, linearmod.NAs)
pvalues = matrix(unlist(pval), nrow = ncol(mtb.NAs), ncol = 3,byrow = T)
apply(pvalues, 2, function(x){min(p.adjust(x, method = 'BH'))})

# Imputation----
# Strategy: "QRILC, a missing data imputation method that performs the imputation
# of left-censored missing data using random draws from a truncated distribution with parameters
# estimated using quantile regression"
install.packages("BiocManager")
library(BiocManager)
BiocManager::install("pcaMethods")
library(pcaMethods)
BiocManager::install("impute")
library(impute)

install.packages('imputeLCMD')
library(imputeLCMD)

#We ASSUME that the data is NOT log-transformed

mtb.numeric = matrix(as.numeric(mtb.by.part3), nrow(mtb.by.part3))

num.mat.1 = mtb.numeric
num.mat.ln = log(num.mat.1)

imp.mtb = impute.QRILC(mtb.numeric)
# Errors produced, "In qnorm((pNAs + 0.001), mean = mean.CDD, sd = sd.CDD) : NaNs produced"
#
# We get the source code and try to see what's going on. 

#The issue was that nFeatures and nSamples were switched

tune.sigma = 1
nFeatures = dim(num.mat)[2]
nSamples = dim(num.mat)[1]
dataSet.imputed = num.mat
QR.obj = list()
for (i in 1:(nSamples)) {
  curr.sample = num.mat.ln[i, ]
  pNAs = length(which(is.na(curr.sample)))/length(curr.sample)
  upper.q = 0.99
  q.normal = qnorm(seq((pNAs + 0.001), (upper.q + 0.001),(upper.q - pNAs)/(upper.q * 100)), mean = 0, sd = 1)
  q.curr.sample = quantile(curr.sample, probs = seq(0.001, 
                                                    (upper.q + 0.001), 0.01), na.rm = T)
  temp.QR = lm(q.curr.sample ~ q.normal)
  QR.obj[[i]] = temp.QR
  mean.CDD = temp.QR$coefficients[1]
  sd.CDD = as.numeric(temp.QR$coefficients[2])
  data.to.imp = rtmvnorm(n = nFeatures, mean = mean.CDD, 
                         sigma = sd.CDD * tune.sigma, upper = qnorm((pNAs+0.001), mean = mean.CDD, sd = sd.CDD), algorithm = c("gibbs"))
  curr.sample.imputed = curr.sample
  curr.sample.imputed[which(is.na(curr.sample))] = data.to.imp[which(is.na(curr.sample))]
  dataSet.imputed[i, ] = curr.sample.imputed
}

num.mat.imputed = dataSet.imputed

# Visual inspection of histograms suggests that undetected values
# have been imputed at low ranges. 
hist(num.mat.imputed[,48],breaks = 100)
hist(num.mat[,48],breaks = 100)

#We backtransform to linear scale
metabolites.imp = exp(num.mat.imputed)
range(as.numeric(mtb.by.part3[,26]),na.rm = T)


# Univariate Regression with significance corrections ----
metabolites.imp

# Treating lung cancer cases as the binary outcome, we code a function (linearmod) that sequentially checks
# every metabolite for significance

linearmod = function(x.indep){
  mod1 = glm(as.numeric(covar[, "case"]) ~ x.indep, family = binomial())
  summa = summary(mod1)
  return(summa$coefficients[2,4])
}

#Extraction of p-values for all the univariate analyses
#of cancer ~ metabolite1, cancer ~ metabolite2 etc.

pvalues = apply(metabolites.imp, 2, linearmod)
pval.log = -log(pvalues)/log(10)
plot(pval.log,ylim = c(0,4))

#Bonferroni correction
bonferroni.cutoff = 0.05/ncol(metabolites.imp)
plot.bonf = -log(bonferroni.cutoff)
abline(h=plot.bonf, col = 'red')

#Benjamini-Hochberg Procedure
pval.BH = p.adjust(pvalues, method = "BH") # None significant at 0.05

sum(pval.BH < 0.05) # NONE !!!!
range(pval.BH) # W O W. Range of BH-corrected pvals is 0.9896816 0.9997920

#Let's try adjusting for Smoking Status
linearmod.adj.for.Smoking = function(x.indep){
  mod1 = glm(as.numeric(covar[, "case"]) ~ x.indep + covar$smoking_status, family = binomial())
  summa = summary(mod1)
  return(summa$coefficients[2,4])
}

#Again, pvalue extraction
pvalues = apply(metabolites.imp, 2, linearmod.adj.for.Smoking)
pval.log = -log(pvalues)/log(10)
plot(pval.log,ylim = c(0,4))

#Bonferroni correction
bonferroni.cutoff = 0.05/ncol(metabolites.imp)
plot.bonf = -log(bonferroni.cutoff)
abline(h=plot.bonf, col = 'red')

#Benjamini-Hochberg Procedure
pval.BH = p.adjust(pvalues, method = "BH") # None significant at 0.05

sum(pval.BH < 0.05) # NONE AGAIN !!!!
range(pval.BH) # Range of BH-corrected pvals is now 0.9529 0.9997920

#Let's try adjusting for Smoking Duration AND age 
linearmod.adj.for.Smoking = function(x.indep){
  mod1 = glm(as.numeric(covar[, "case"]) ~ x.indep + covar$packyears + covar$Monocytes + covar$bmi + covar$B+covar$Gel.status, family = binomial())
  summa = summary(mod1)
  return(summa$coefficients[2,4])
}

#Again, pvalue extraction
pvalues = apply(metabolites.imp, 2, linearmod.adj.for.Smoking)
pval.log = -log(pvalues)/log(10)
plot(pval.log,ylim = c(0,4))

#Bonferroni correction
bonferroni.cutoff = 0.05/ncol(metabolites.imp)
plot.bonf = -log(bonferroni.cutoff)
abline(h=plot.bonf, col = 'red')

#Benjamini-Hochberg Procedure
pval.BH = p.adjust(pvalues, method = "BH") # None significant at 0.05

sum(pval.BH < 0.05) # NONE AGAIN !!!!

range(pval.BH) # Range of BH-corrected pvals is now ↓ 0.86855 0.9997920






# Multivariate Approaches ----

# 1. PCA
mtb.pca = prcomp(metabolites.imp, center = T, scale. = T)

pca.numeric = unlist(mtb.pca[1])
sum(pca.numeric[1:220]) / sum(pca.numeric)


mtb.pca$rotation


