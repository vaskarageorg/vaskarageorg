# 31 / 1 / 2020
NOTES--------------------------------------------------------------------------------------------------------------------------------------------------------------------------
# Work for next meeting: Univariate models of the form: 1. lm( Adductomics ~ cancer + age + gender ), 2. lm(Adductomics ~ cancer + age + gender + technical confounders)
#                                                       3. ANOVA 2 VS 1, within this we keep the p value, I have some relevant code in liens 139+ for keeping the p value
#                                                        from the model
#                                                        lines 
#                        PCA for every single dataset separately
#                       Check what group penalisation means, we have to enter background knwoledge in a lasso regression, eg. inflammatory
#                        proteins are associated with each other.
#NOTES: Maybe we can add technical confounders as random effects: lmer package. eg. random effect (1 | chip)




#28 / 1/ 2020 : UPDATE

# Let's work on this as reference.

# What I've done is in the headers. Basically, it's imputation, univariate regression with correction for metabolomics.

#24 / 1/ 2020 : UPDATE. 
#This is the code with some stuff for preprocessing.

#We will go thorugh the first Aim (Univariate analyses)

#Rebecca: Protein + Covars----------------------------------------------------------------------------------------------------
library(tidyverse)
library(dplyr)
library(stringr)
library(reshape2)
library(tidyr)
library(devtools)
# package for PCA
library(FactoMineR)
library(factoextra)
library(ggbiplot)
library(ggplot2)
# package for iso forest
library(solitude)
# data preprocessing
# drop rows with na
proteins<-Proteins%>% drop_na()
# create new col "ID"
proteins$Indiv.ID <- row.names(proteins)
#identify individuals with repeated measurement
repeated<-proteins %>%filter(str_detect(Indiv.ID, "_2"))
#manipulate ID string
proteins$Indiv.ID<-str_sub(proteins$Indiv.ID, 1, 7)
#group by ID and take avg for repeated measurement
prot <- proteins %>%
  group_by(Indiv.ID) %>%
  summarize_each(funs(mean))
# check the above code
check<-proteins%>%filter(Indiv.ID==2101850 |Indiv.ID==	2112935)
check_group<-df%>%filter(Indiv.ID==2101850 |Indiv.ID==	2112935)
# cal correlation matrix
cormat <- round(cor(prot),2)
melted_cormat <- melt(cormat)
head(melted_cormat)
#plot correlation matrix
ggplot(data = melted_cormat, aes(x=Var1, y=Var2, fill=value)) + geom_tile()
# get tri of the matrix
get_lower_tri<-function(cormat){
  cormat[upper.tri(cormat)] <- NA
  return(cormat)
}
lower_tri <- get_lower_tri(cormat)
lower_tri
melted_cormat <- melt(lower_tri, na.rm = TRUE)
head(melted_cormat)
#sorted correlation values
df_sorted<- melted_cormat[with(melted_cormat, order(value)), ]

# select important features from Covariates
features<-Covariates%>%select("Indiv.ID","case","age.sample","gender")
# merge covar with proteomics
join<-inner_join(features,prot)
var<-join[,3:96]
class<-join[,2]
# conduct PCA analysis
pca <- prcomp(var,
                 center = TRUE,
                 scale. = TRUE) 
summary(pca)
fviz_eig(pca)
g <- ggbiplot(pca, obs.scale = 1, var.scale = 1, 
              groups = class, ellipse = TRUE, 
              circle = TRUE)
g
fviz_pca_ind(pca,
             col.ind = "cos2", # Color by the quality of representation
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07")
)
fviz_pca_var(pca,
             col.var = "contrib", # Color by contributions to the PC
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
           
)
# Eigenvalues
eig.val <- get_eigenvalue(pca)
eig.val
res.ind <- get_pca_ind(pca)
res.ind$coord          # Coordinates
res.ind$contrib        # Contributions to the PCs
res.ind$cos2           # Quality of representation
# use first PC to identify outliers
# results show around 32 outliers!!!!!
# CHECK with tutors, I am not sure if my approach is correct!!
# Did not find a tutorial on PCA outlier detection
coord<-as.data.frame(res.ind$coord)
dim<-coord[,1]
out<-as.data.frame(dim)
out$ID <- seq.int(nrow(out))
outlier<-out%>%filter(dim>8)
# another outlier detection approach called isolation forest
# results show no outlier for proteomics!!!!!
#score close to 1 means outlier, <0.5 means normal obs
iso <- isolationForest$new()
#proX <- Proteins[, setdiff(colnames(Proteins), "proteins")]
prot_iso<-prot[,-1]
iso$fit(df)
print(iso$scores)
# identify outliers by the distribution of score
quantile(iso$scores$anomaly_score
         , probs = seq(0, 1, length.out = 11))

#Tarana: Adductomics + Covars-------------------------------------------------------------------------------------------------


library(stringr)
work_dir<- "/rds/general/user/tm2119/home/TDS_Session2"

## Adductomics data cleaning
adm<- readRDS('Adductomics/Adductomics_imputed.rds')
adm

dim(adm)

row.adm <- rownames(adm)

row.adm.clean <-gsub("_1$",".1",row.adm)
row.adm.clean
row.adm.clean <-gsub("_2$",".2",row.adm.clean)
row.adm.clean
row.adm.fin <-gsub(".*_","",row.adm.clean)
row.adm.fin
row.adm.fin<-str_sub(row.adm.fin,-20, -3)
head(row.adm.fin)

rownames(adm)<-row.adm.fin
rownames(adm)

#LOG TRANSFORM DATA FOR ADDUCTOMICS
adm.log = log(adm)
head(adm.log)
dim(adm.log)


#Average every two rows
M <- matrix(unlist(c(adm.log)), ncol = 2, byrow = TRUE)
M <- cbind(M, rowMeans(M))
M <- matrix(c(t(M)),ncol = ncol(adm.log), byrow = FALSE)

---------------# add row names and column names 
row.names <- matrix(rownames(adm.log), ncol = 2 ,byrow = TRUE)
rownames(M) <- c(t(cbind(row.names, apply(row.names,1, paste, collapse = "_"))))
colnames(M) <- colnames(adm.log)
rownames(M)
#Create new dataframe only with mean values (an index from row 3 to nrow (number of rows of the table) every 3 rows). 
M.new = M[seq(3, nrow(M), 3), ]

#Since some samples has 2 duplicates(4 in total), hence we are averaging two means and deleting the rest of duplicates
#In total would be 197 samples

rownames(M.new)
M.new.2466652.1<-M.new[157,]
M.new.2466652.2<-M.new[158,]
X2466652<-((M.new.2466652.1)+(M.new.2466652.2))/2
M.new<-rbind(M.new,X2466652)


#Drop the other two
drop.2466652 <-M.new[-c(157),]
M.new<-drop.2466652
drop.2466652.1 <-M.new[-c(158),]
M.new<-drop.2466652.1

dim(M.new)

tail(M.new)

#Do the same for 2224825
rownames(M.new)

M.new.2224825.1<-M.new[32,]
M.new.2224825.2<-M.new[33,]
X2224825<-((M.new.2224825.1)+(M.new.2224825.2))/2

M.new<-rbind(M.new,X2224825)

#Drop the other two
drop.2224825 <-M.new[-c(32),]
M.new<-drop.2224825

drop.2224825.1 <-M.new[-c(33),]
M.new<-drop.2224825.1

dim(M.new)

tail(M.new)

#Rename rows and make
rownames(M.new)[197]<-"2224825_2224825"
rownames(M.new)[197]

rownames(M.new)[196]<-"2466652_2466652"
rownames(M.new)

sort(M.new)

head(M.new)
#Rename all rows. Samples now 197 and all named properly
library(dplyr)
row.M.new<-rownames(M.new)
row.M.new<-substr(row.M.new, start=1, stop=7)
row.M.new

#Create column Indiv.ID that will match the same with covariates
M.new<-cbind(Indiv.ID=row.M.new,M.new)
head(M.new)
rownames(M.new)<-M.new
rownames(M.new)
head(M.new)

#Cleaning for Covariates
covariates <- readRDS('Covariates.rds')
covariates
str(covariates$Indiv.ID)

#Subset only those where Indiv.ID==7 characters
covariates$Indiv.ID=as.character(covariates$Indiv.ID)
covariates = covariates[(which(nchar(covariates$Indiv.ID) == 7)),]
#Group two datasets by Indiv.ID and drop the rest.
covariates$Indiv.ID=as.numeric(covariates$Indiv.ID)
new_covariates<-covariates%>%filter(Indiv.ID>2220020&Indiv.ID<2470519)
new_covariates
dim(new_covariates)
M.new=as.data.frame(M.new)

#Join two datasets(adductomics+covariates) by Indiv.ID
adm.covar <- join(M.new, new_covariates, by = c("Indiv.ID"))
adm.covar
dim(adm.covar)

#UNIVARIATE LINEAR MODELS TO FOLLOW:


#Vasilis: Metabolomics + Covars------------------------------------------------------------------------------------------------

# Metabolome Script

# Load Files, Missingness Investigation----
covar <- readRDS('Covariates.rds')

#Relevelling Gel Status so that NA is a value. OK's are '1', Gel's are '2', NA's are 'Missing'
covar$Gel.status = ifelse(is.na(covar$Gel.status), 'Missing', covar$Gel.status)

mtb = read.csv("/rdsgpfs/general/project/hda_tds/live/Mechanomics/Metabolites/Lung cancer feature table RP NEG_231019.csv")

mtb.by.participant = t(as.matrix(mtb))


#We fix the ID's of participants in mtb and covar datasets so that we can later join the two sets.
library(stringr)

rowmetabol <- rownames(mtb.by.participant)
rowmetabol.clean <- gsub("_1$",".1",rowmetabol)
rowmetabol.clean <- gsub("_2$",".2",rowmetabol.clean)
rowmetabol.fin <- gsub(".*_","",rowmetabol.clean)
rownames(mtb.by.participant) <- rowmetabol.fin

# Excluding 17 blanks in the mtb.by.paricipant dataset
mtb.by.part = mtb.by.participant[18:667,]

names.covariates = sort(as.numeric(rownames(covar)))
names.metabol = sort(as.numeric(rownames(mtb.by.part)))
(names.covariates == names.metabol)
#THere is a discrepancy at position [295]. Namely, there is an extra ID of 2103767 in metabol dataset
names.covariates[295]
names.metabol[295]

#We look further to find the other discrepancy
names.covariates.plus295 = names.covariates[295:648]
names.metabol.plus295 = names.metabol[296:650]
names.covariates.plus295 == names.metabol.plus295

# One More in position 47
names.covariates.plus295[48]
names.metabol.plus295[48]

# The extra ID is 2106943. SO, IN THE MTB dataset, there are 2 MEASUREMENTS for 2 ID's,
# Namely: 2106943, 2103767. We can either take the mean or use mixed models. 

# For these 2 observations, to reduce complexity,
# and since it's only 2/650 observations, we'll take the mean wherever there are 2 observations and
# the observed value where one of them is NA

length(mtb.by.part[rownames(mtb.by.part) == 2106943])
length(mtb.by.part[rownames(mtb.by.part) == 2103767])

vector.2106943 = matrix(as.numeric(mtb.by.part[rownames(mtb.by.part) == 2106943,]), byrow = F, nrow = 2)
vector.2106943[1:2, 120:130]

vec1 = as.data.frame(vector.2106943)
vec1.3 = ifelse(is.na(vec1[1,1:4828]) | is.na(vec1[2,1:4828]), 1,0 )
vec.all = rbind(vec1, vec1.3)
vec.all[is.na(vec.all)] <- 0

# Probably not the fastest way but still works. Wherever there is 1 NA, we take the value. WHerevere both
# observations are available, we take the mean. NA's are changed to 0's for facilitating code

mean.or.NA = ifelse(vec.all[3,] == 0, (vec.all[1,] + vec.all[2,])/2, vec.all[,1] +  vec.all[2,])
meanNA2106943 = unlist(mean.or.NA)
meanNA2106943[meanNA2106943 == 0] <- NA
mtb.by.part2 = rbind(mtb.by.part, meanNA2106943)

#Dropping the other rows
drop.index.2106943 = which(rownames(mtb.by.part2) == "2106943")
mtb.by.part2 = mtb.by.part2[-drop.index.2106943,]
dim(mtb.by.part2)

# The same process for ID 2103767. rownames(mtb.by.part2) lathos
vector.2103767 = matrix(as.numeric(mtb.by.part2[rownames(mtb.by.part2) == 2103767,]), byrow = F, nrow = 2)
vector.2103767[1:2, 120:130]

vec1 = as.data.frame(vector.2103767)
vec1.3 = ifelse(is.na(vec1[1,1:4828]) | is.na(vec1[2,1:4828]), 1,0 )
vec.all = rbind(vec1, vec1.3)
vec.all[is.na(vec.all)] <- 0

# Probably not the fastest way but still works. Wherever there is 1 NA, we take the value. WHerevere both
# observations are available, we take the mean. NA's are changed to 0's for facilitating code

mean.or.NA = ifelse(vec.all[3,] == 0, (vec.all[1,] + vec.all[2,])/2, vec.all[,1] +  vec.all[2,])
meanNA2103767 = unlist(mean.or.NA)
meanNA2103767[meanNA2103767 == 0] <- NA
mtb.by.part3 = rbind(mtb.by.part2, meanNA2103767)

#Dropping the other rows
drop.index.2103767 = which(rownames(mtb.by.part3) == "2103767")
mtb.by.part3 = mtb.by.part3[-drop.index.2103767,]
dim(mtb.by.part3)

#648, now they match with covars

# Firstly, we will be excluding those metabolites for whom >70% of the values are missing
mtb.NAs = ifelse(is.na(mtb.by.part3) == T, 1, 0)

na.proportion.vector = apply(mtb.NAs, 1, mean)

hist(na.proportion.vector,breaks = 1000)
# DATA-DRIVEN choice of cut-off: 0.65

mtb.lessthan60 = mtb.by.part3[which(na.proportion.vector < 0.6),]
dim(mtb.lessthan65)
  
# In the remaining dataset, we will be treating missing or not as a binary outcome 
# 
# and run logistic regression as follows: missingness ~ age + gender + BMI + ...
#
# We will accordingly correct for multiple comparisons
linearmod.NAs = function(metabolite.missing){
  mod1 = glm(metabolite.missing ~ covar$age.sample + covar$case + covar$cohort ,
             family = binomial())
  summa = summary(mod1)
  age.pval = summa$coefficients[2,4]
  ccstatus.pval = summa$coefficients[3,4]
  cohort.pval = summa$coefficients[4,4]
  df.pval = data.frame(summa$coefficients[2,4], summa$coefficients[3,4], summa$coefficients[4,4])
  colnames(df.pval) = NULL
  return(df.pval)
  
}

pval = apply(mtb.NAs, 2, linearmod.NAs)
pvalues = matrix(unlist(pval), nrow = ncol(mtb.NAs), ncol = 3,byrow = T)
apply(pvalues, 2, function(x){min(p.adjust(x, method = 'BH'))})

# Imputation----
# Strategy: "QRILC, a missing data imputation method that performs the imputation
# of left-censored missing data using random draws from a truncated distribution with parameters
# estimated using quantile regression"
install.packages("BiocManager")
library(BiocManager)
BiocManager::install("pcaMethods")
library(pcaMethods)
BiocManager::install("impute")
library(impute)

install.packages('imputeLCMD')
library(imputeLCMD)

#We ASSUME that the data is NOT log-transformed

mtb.numeric = matrix(as.numeric(mtb.by.part3), nrow(mtb.by.part3))

num.mat.1 = mtb.numeric
num.mat.ln = log(num.mat.1)

imp.mtb = impute.QRILC(mtb.numeric)
# Errors produced, "In qnorm((pNAs + 0.001), mean = mean.CDD, sd = sd.CDD) : NaNs produced"
#
# We get the source code and try to see what's going on. 

#The issue was that nFeatures and nSamples were switched

tune.sigma = 1
nFeatures = dim(num.mat)[2]
nSamples = dim(num.mat)[1]
dataSet.imputed = num.mat
QR.obj = list()
for (i in 1:(nSamples)) {
  curr.sample = num.mat.ln[i, ]
  pNAs = length(which(is.na(curr.sample)))/length(curr.sample)
  upper.q = 0.99
  q.normal = qnorm(seq((pNAs + 0.001), (upper.q + 0.001),(upper.q - pNAs)/(upper.q * 100)), mean = 0, sd = 1)
  q.curr.sample = quantile(curr.sample, probs = seq(0.001, 
                                                    (upper.q + 0.001), 0.01), na.rm = T)
  temp.QR = lm(q.curr.sample ~ q.normal)
  QR.obj[[i]] = temp.QR
  mean.CDD = temp.QR$coefficients[1]
  sd.CDD = as.numeric(temp.QR$coefficients[2])
  data.to.imp = rtmvnorm(n = nFeatures, mean = mean.CDD, 
                         sigma = sd.CDD * tune.sigma, upper = qnorm((pNAs+0.001), mean = mean.CDD, sd = sd.CDD), algorithm = c("gibbs"))
  curr.sample.imputed = curr.sample
  curr.sample.imputed[which(is.na(curr.sample))] = data.to.imp[which(is.na(curr.sample))]
  dataSet.imputed[i, ] = curr.sample.imputed
}

num.mat.imputed = dataSet.imputed

# Visual inspection of histograms suggests that undetected values
# have been imputed at low ranges. 
hist(num.mat.imputed[,48],breaks = 100)
hist(num.mat[,48],breaks = 100)

#We backtransform to linear scale
metabolites.imp = exp(num.mat.imputed)
range(as.numeric(mtb.by.part3[,26]),na.rm = T)


# Univariate Regression with significance corrections ----
metabolites.imp

# Treating lung cancer cases as the binary outcome, we code a function (linearmod) that sequentially checks
# every metabolite for significance

linearmod = function(x.indep){
  mod1 = glm(as.numeric(covar[, "case"]) ~ x.indep, family = binomial())
  summa = summary(mod1)
  return(summa$coefficients[2,4])
}

#Extraction of p-values for all the univariate analyses
#of cancer ~ metabolite1, cancer ~ metabolite2 etc.

pvalues = apply(metabolites.imp, 2, linearmod)
pval.log = -log(pvalues)/log(10)
plot(pval.log,ylim = c(0,4))

#Bonferroni correction
bonferroni.cutoff = 0.05/ncol(metabolites.imp)
plot.bonf = -log(bonferroni.cutoff)
abline(h=plot.bonf, col = 'red')

#Benjamini-Hochberg Procedure
pval.BH = p.adjust(pvalues, method = "BH") # None significant at 0.05

sum(pval.BH < 0.05) # NONE !!!!
range(pval.BH) # W O W. Range of BH-corrected pvals is 0.9896816 0.9997920

#Let's try adjusting for Smoking Status
linearmod.adj.for.Smoking = function(x.indep){
  mod1 = glm(as.numeric(covar[, "case"]) ~ x.indep + covar$smoking_status, family = binomial())
  summa = summary(mod1)
  return(summa$coefficients[2,4])
}

#Again, pvalue extraction
pvalues = apply(metabolites.imp, 2, linearmod.adj.for.Smoking)
pval.log = -log(pvalues)/log(10)
plot(pval.log,ylim = c(0,4))

#Bonferroni correction
bonferroni.cutoff = 0.05/ncol(metabolites.imp)
plot.bonf = -log(bonferroni.cutoff)
abline(h=plot.bonf, col = 'red')

#Benjamini-Hochberg Procedure
pval.BH = p.adjust(pvalues, method = "BH") # None significant at 0.05

sum(pval.BH < 0.05) # NONE AGAIN !!!!
range(pval.BH) # Range of BH-corrected pvals is now 0.9529 0.9997920

#Let's try adjusting for Smoking Duration AND age 
linearmod.adj.for.Smoking = function(x.indep){
  mod1 = glm(as.numeric(covar[, "case"]) ~ x.indep + covar$packyears + covar$Monocytes + covar$bmi + covar$B+covar$Gel.status, family = binomial())
  summa = summary(mod1)
  return(summa$coefficients[2,4])
}

#Again, pvalue extraction
pvalues = apply(metabolites.imp, 2, linearmod.adj.for.Smoking)
pval.log = -log(pvalues)/log(10)
plot(pval.log,ylim = c(0,4))

#Bonferroni correction
bonferroni.cutoff = 0.05/ncol(metabolites.imp)
plot.bonf = -log(bonferroni.cutoff)
abline(h=plot.bonf, col = 'red')

#Benjamini-Hochberg Procedure
pval.BH = p.adjust(pvalues, method = "BH") # None significant at 0.05

sum(pval.BH < 0.05) # NONE AGAIN !!!!

range(pval.BH) # Range of BH-corrected pvals is now â†“ 0.86855 0.9997920






# Multivariate Approaches ----

# 1. PCA
mtb.pca = prcomp(metabolites.imp, center = T, scale. = T)

pca.numeric = unlist(mtb.pca[1])
sum(pca.numeric[1:220]) / sum(pca.numeric)


mtb.pca$rotation


