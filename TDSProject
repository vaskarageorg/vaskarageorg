NOTES FROM THE MEETING WITH MARC:
1.	Sensitivity analysis (univariate analysis) for non-imputed and imputed data -be careful of betas and p-values as you are comparing two data where imputed has less observations than non-imputed. (I think we need to do it separately for each proteins)
2.	Present the proportion of imputed values
3.	For covariates(smoking) you read literature and you can also do different models by using different smoking indicating variable and compare models
Also, can subset non-smokers and do analysis to compare with smokers
4.	QC.Warning showing warning are outliers (remove them)
5.	For imputation 50% is ok, 70% is too high
6.	For outlier detection stick to one method
7.	Join the whole dataset and analyse (histological subtypes for lung cancer)
You can join OMICS two by two and make analysis
8.	Donâ€™t remove subclinical effects of the disease




#Code up tp PLS FOR ADDUCTOMICS--------------------------------------------------------
library(stringr)
work_dir<- "/rds/general/user/tm2119/home/TDS_Session2"

#Adductomics cleaning-----
adm<- readRDS('Adductomics/Adductomics_imputed.rds')
adm<-as.data.frame(adm)

str(adm)
dim(adm)

rownames(adm)
row.adm <- rownames(adm)

row.adm.clean <-gsub("_1$",".1",row.adm)
row.adm.clean
row.adm.clean <-gsub("_2$",".2",row.adm.clean)
row.adm.clean
row.adm.fin <-gsub(".*_","",row.adm.clean)
row.adm.fin
rownames(adm)<-row.adm.fin
rownames(adm)
rownames(adm)[65]<-"2224825.3"
rownames(adm)[66]<-"2224825.4"

rownames(adm)[314]<-"2466652.4"
rownames(adm)[315]<-"2466652.3"
rownames(adm)[389]<-"2470231.1"
rownames(adm)[393]<-"2470381.2"




#LOG TRANSFORM DATA FOR ADDUCTOMICS
adm.log<-log(adm)
is.matrix(adm.log)
head(adm.log)
str(adm.log)

#Create column Indiv.ID
adm.log <- cbind(Indiv.ID = rownames(adm.log),adm.log)
adm.log

#Technical covariates data----
adm_tc <- readRDS("/rdsgpfs/general/project/hda_tds/live/Mechanomics/Adductomics/Adductomics_technical_covariates.rds")
adm_tc


row.adm.tc <- rownames(adm_tc)
row.adm.clean.tc <-gsub("_1$",".1",row.adm.tc)
row.adm.clean.tc
row.adm.clean.tc <-gsub("_2$",".2",row.adm.clean.tc)
row.adm.clean.tc
row.adm.fin.tc <-gsub(".*_","",row.adm.clean.tc)
row.adm.fin.tc
row.adm.fin.tc[65]<-"2224825.3"
row.adm.fin.tc[66]<-"2224825.4"
row.adm.fin.tc[314]<-"2466652.4"
row.adm.fin.tc[315]<-"2466652.3"
row.adm.fin.tc[389]<-"2470231.1"
row.adm.fin.tc[393]<-"2470381.2"
row.adm.fin.tc
rownames(adm_tc)<-row.adm.fin.tc
rownames(adm_tc)
dim(adm_tc)

#Create Indiv.ID for adm_tc
adm_tc<- cbind(Indiv.ID = rownames(adm_tc),adm_tc)
dim(adm_tc)

#Merge TWO datasets----
adm.log.tc<-merge(adm.log, adm_tc, by=c("Indiv.ID"))
dim(adm.log.tc)
table(is.na(adm.log.tc))
str(adm.log.tc)


#Detect outliers using "solitude"----
install.packages("solitude")
library(solitude)

#score close to 1 means outlier, <0.5 means normal obs
admX <- adm.log[,2:44]
iso <- isolationForest$new()
iso$fit(admX)
print(iso$scores)
plot(iso$scores)
# identify outliers by the distribution of score
quantile(iso$scores$anomaly_score
         , probs = seq(0, 1, length.out = 11))


#PCA Analysis----
numeric.adm<-adm.log.tc[,2:44]
pca1<-prcomp(numeric.adm, center = TRUE, scale.=TRUE)
plot(pca1, type="l")

#USING METHOD FROM TUTORIAL
ev = with(pca1, pca1$sdev^2/sum(pca1$sdev^2))
plot(ev, pch = 19, col = "navy", xlab = "# of PCs",
     ylab = "Proportion of EV", ylim = c(0, 1.2), cex = 0.3) 
points(cumsum(ev), pch = 19, col = "tomato", cex = 0.3) 
legend("top", pch = 19, col = c("navy", "tomato"),
legend = c("EV", "Cumulative EV"), cex = 0.4, horiz = T)
sum(!cumsum(ev) > 0.9)
print(pca1$rotation)
pca1%>%biplot(cex=.6)


#Deal with covariates----
install.packages("ggplot2")
library(ggplot2)
library(dplyr)
cov<-covariates%>%select("gender","case","age.sample","CSI")
cov

#Create adm.log.tc1 merge 3 datasets----
cov$EPIC_ID<-rownames(cov)
head(cov)
adm.log.tc1<-merge(adm.log.tc,cov,by=c("EPIC_ID"),all.x = TRUE)
head(adm.log.tc1)
str(adm.log.tc1)
#Run PCA---- 
adm.pca<-adm.log.tc1[,3:45]
str(adm.pca)
pca1<-prcomp(adm.pca, center = TRUE, scale.=TRUE)
plot(pca1, type="l")

#USING METHOD FROM TUTORIAL
ev = with(pca1, pca1$sdev^2/sum(pca1$sdev^2))
plot(ev, pch = 19, col = "navy", xlab = "# of PCs",
     ylab = "Proportion of EV", ylim = c(0, 1.2), cex = 0.3) 
points(cumsum(ev), pch = 19, col = "tomato", cex = 0.3) 
legend("top", pch = 19, col = c("navy", "tomato"),
       legend = c("EV", "Cumulative EV"), cex = 0.4, horiz = T)
sum(!cumsum(ev) > 0.9)
print(pca1$rotation)
pca1%>%biplot(cex=.6)

#Univariate Model---------------------------------------------------------------------
install.packages("omics")
suppressPackageStartupMessages(library(omics))

adm_noise<-adm.log[,2:44]

model_univ<-mlmer(adm_noise~(1|EPIC_ID)+(1|Analytical.batch)+(1|Extraction.batch)+(1|Gel.status)+gender+case+age.sample,vars = "case",save.residuals=TRUE, data=adm.log.tc1)
coeff<-data.frame(model_univ$coefficients)
sum(p.adjust(coeff$pval, method = "BH") < 0.05)
sum(p.adjust(coeff$pval, method = "bonf") < 0.05)
sum(p.adjust(coeff$pval, method = "none") < 0.05)
#Denoising Data/Mixed Models-----------------------------------------------------------------------------------
install.packages("omics")
suppressPackageStartupMessages(library(omics))

adm.only <- adm.log.tc1[,3:45]
str(adm.only)
model2<-mlmer(adm.only~(1|Analytical.batch)+(1|Extraction.batch)+(1|Gel.status),save.residuals=TRUE, data=adm.log.tc1)
model2$coefficients
X=model2$residuals
saveRDS(X, "Adductomics/Adductomics_denoised.rds")
X=readRDS("Adductomics/Adductomics_denoised.rds")
head(X)

#After denoising data RUN PCA Analysis again----
X=readRDS("Adductomics/Adductomics_denoised.rds")
head(X)
pcaX = prcomp(X, center = TRUE, scale. = TRUE)
print(pcaX)
plot(pcaX, type="l")
ev1 = with(pcaX, pcaX$sdev^2/sum(pcaX$sdev^2))
plot(ev1, pch = 19, col = "navy", xlab = "# of PCs",
     ylab = "Proportion of EV1", ylim = c(0, 1.2), cex = 0.3) 
points(cumsum(ev1), pch = 19, col = "tomato", cex = 0.3) 
legend("top", pch = 19, col = c("navy", "tomato"),
       legend = c("EV1", "Cumulative EV1"), cex = 0.4, horiz = T)
sum(!cumsum(ev1) > 0.9)

print(pcaX$rotation)
pcaX%>%biplot(cex=.6)                                                                                                                          

#PHEATMAP----
library(pheatmap)
str(adm.only)
adm.only=as.numeric(adm.only)
mycor=cor(adm[,1:43], use="complete.obs")
pheatmap(mycor, cluster_cols = FALSE, cluster_rows = FALSE, breaks = seq(-1,1, length.out = 100), show_rownames = FALSE, 
         show_colnames = FALSE)



#Lasso Model----
install.packages("glmnet")
suppressPackageStartupMessages(library(glmnet))
X=readRDS("Adductomics/Adductomics_denoised.rds")
head(X)
Y<-adm.log.tc1$case


plot(density(Y), las = 1, main = "", xlab = "", ylab = "",
     lwd = 2, col = "navy")

set.seed(1000)
model.lasso=cv.glmnet(x=X,y=Y, alpha=1,family="binomial")
model.lasso$lambda.1se
plot(model.lasso)
model.lasso.fitted = glmnet(x=X,y=Y,alpha = 1, family = "binomial")

table(coef(model.lasso,s="lambda.1se")[-1]!=0)
betas=coef(model.lasso, s='lambda.1se')[-1]
names(betas)=rownames(coef(model.lasso, s='lambda.1se'))[-1]
plot(betas[betas!=0], type = 'h', col='navy', lwd=3, xaxt='n', xlab='', ylab=expression(beta))
axis(side = 1, at = 1:sum(betas!=0), labels = names(betas)[betas!=0], las=2)
abline(h=0, lty=2)


#Stability Lasso-----------------
LassoSub = function(k = 1,Xdata, Ydata) {
        set.seed(k)
        s0 = sample(which(adm.log.tc1$case==0), 
                    size = 0.8 * sum(adm.log.tc1$case==0)) # subsampling controls
        s1 = sample(which(adm.log.tc1$case==1), 
                    size = 0.8 * sum(adm.log.tc1$case==1)) # subsampling cases
        s=c(s0,s1)
        Xsub = Xdata[s, ]
        Ysub = Ydata[s]
        model.sub = cv.glmnet(x = Xsub, y = Ysub, alpha = 1, family="binomial")
        coef.sub = coef(model.sub, s = "lambda.1se")[-1]
        return(coef.sub)
}

niter = 100
lasso.stab = sapply(1:niter, FUN = LassoSub, 
                    Xdata = X, Ydata = adm.log.tc1$case)


lasso.prop = apply(lasso.stab, 1, FUN = function(x) {
        sum(x != 0)/length(x)
})
names(lasso.prop) = colnames(X)

lasso.prop = sort(lasso.prop, decreasing = TRUE)
plot(lasso.prop, type = "h", col = "navy",
     lwd = 3, xaxt = "n", xlab = "", ylab = "Selection proportion",
     ylim = c(0, 1.05), las = 1)
text(lasso.prop + 0.07, 
     labels = names(lasso.prop), 
     pos = 3, srt = 90, cex = 0.7)

--------------------------------------------------------------------------------------------------------------------------










#Lasso Model---- FOR VASILIS
install.packages("glmnet")
library(glmnet)

X=readRDS("Adductomics/Adductomics_denoised.rds")
head(X)
X=as.data.frame(X)
X<- cbind(Indiv.ID = rownames(X),X)
X1<-X[,2:44]
Y<-adm.log.tc1$case

suppressPackageStartupMessages(library(glmnet))

plot(density(Y), las = 1, main = "", xlab = "", ylab = "",
     lwd = 2, col = "navy")
model.lasso=cv.glmnet(X1,Y, alpha=1)
plot(model.lasso)


#UNIVARIATE ANALYSIS
model.mtb = mlmer(metabolites.only ~ case + age.sample + gender + (1 | merged.df$Plate),
                  vars = 'case', data=merged.df, save.residuals = TRUE)

view(model.mtb$coefficients)

model.mtb$coefficients

pvalues.from.univariate = model.mtb$coefficients[,3]
hist(pvalues.from.univariate)

pvalues = apply(metabolites.imp, 2, linearmod)
pval.log = -log(pvalues)/log(10)
plot(pval.log,ylim = c(0,6))


#13th Feb 2020

#CODE FOR ADDUCTOMICS WHEN INDIV.ID WAS NOT AVERAGED. -----------------------STILL MESSY/UPLOADED FOR REBECCA TO LOOK AT LINEAR MIXED MODELS
library(stringr)
work_dir<- "/rds/general/user/tm2119/home/TDS_Session2"

## Adductomics-----
adm<- readRDS('Adductomics/Adductomics_imputed.rds')
adm<-as.data.frame(adm)
outlier(adm, method="median", addthres=TRUE)
str(adm)
dim(adm)

rownames(adm)
row.adm <- rownames(adm)

row.adm.clean <-gsub("_1$",".1",row.adm)
row.adm.clean
row.adm.clean <-gsub("_2$",".2",row.adm.clean)
row.adm.clean
row.adm.fin <-gsub(".*_","",row.adm.clean)
row.adm.fin
rownames(adm)<-row.adm.fin
rownames(adm)
rownames(adm)[65]<-"2224825.3"
rownames(adm)[66]<-"2224825.4"
rownames(adm)[314]<-"2466652.4"
rownames(adm)[315]<-"2466652.3"
rownames(adm)[389]<-"2470231.1"
rownames(adm)[393]<-"2470381.2"
rownames(adm)

#Create column Indiv.ID
adm.log <- cbind(Indiv.ID = rownames(adm.log),adm.log)
adm.log





#LOG TRANSFORM DATA FOR ADDUCTOMICS
adm.log<-log(adm)
is.matrix(adm.log)
head(adm.log)
str(adm.log)

#Technical covariates data
adm_tc <- readRDS("/rdsgpfs/general/project/hda_tds/live/Mechanomics/Adductomics/Adductomics_technical_covariates.rds")
adm_tc


row.adm.tc <- rownames(adm_tc)
row.adm.clean.tc <-gsub("_1$",".1",row.adm.tc)
row.adm.clean.tc
row.adm.clean.tc <-gsub("_2$",".2",row.adm.clean.tc)
row.adm.clean.tc
row.adm.fin.tc <-gsub(".*_","",row.adm.clean.tc)
row.adm.fin.tc
row.adm.fin.tc[65]<-"2224825.3"
row.adm.fin.tc[66]<-"2224825.4"
row.adm.fin.tc[314]<-"2466652.4"
row.adm.fin.tc[315]<-"2466652.3"
row.adm.fin.tc[389]<-"2470231.1"
row.adm.fin.tc[393]<-"2470381.2"
row.adm.fin.tc
rownames(adm_tc)<-row.adm.fin.tc
rownames(adm_tc)
dim(adm_tc)

#Create Indiv.ID for adm_tc
adm_tc<- cbind(Indiv.ID = rownames(adm_tc),adm_tc)
dim(adm_tc)

#Merge TWO datasets
adm.log.tc<-merge(adm.log, adm_tc, by=c("Indiv.ID"))
dim(adm.log.tc)
table(is.na(adm.log.tc))
str(adm.log.tc)

#PCA Analysis
pca.cov<-covariates%>%select("age.sample","storage_time","smok_intensity","CSI","bmi")
pca.cov
table(is.na(pca.cov))
pca.cov=na.omit(pca.cov)
table(is.na(pca.cov))
numeric.adm<-adm[,1:43]
#pca<-prcomp(pca.cov,center = TRUE, scale. = TRUE)
#summary(pca)
#pca%>%biplot(cex=.7)

pca1<-prcomp(numeric.adm, center = TRUE, scale.=TRUE)
summary(pca1)
pca1$sdev^2
print(pca1$rotation)
pca1%>%biplot(cex=.6)

#Deal with covariates
install.packages("ggplot2")
library(ggplot2)
library(dplyr)
cov<-covariates%>%select("Indiv.ID","gender","case","age.sample")
cov

#Create EPIC_ID in covariatesso we can join with adm.log.tc
cov$EPIC_ID<-rownames(cov)
head(cov)
adm.log.tc1<-merge(adm.log.tc,cov,by=c("EPIC_ID"))
adm.log.tc1

# outlier detection and normalizing
outlier_norm <- function(x){
  qntile <- quantile(x, probs=c(.25, .75))
  caps <- quantile(x, probs=c(.05, .95))
  H <- 1.5 * IQR(x, na.rm = T)
  x[x < (qntile[1] - H)] <- caps[1]
  x[x > (qntile[2] + H)] <- caps[2]
  return(x)
}
adm.log.tc1$age.sample=outlier_norm(adm.log.tc1$age.sample)

ggplot(adm.log.tc1, mapping = aes(x = case, y = age.sample, fill = case)) + 
  geom_boxplot(outlier.colour = "red", outlier.shape = 8, outlier.size = 4) + 
  facet_wrap(~gender)


#Mixed Models-----------------------------------------------------------------------------------
install.packages("omics")
suppressPackageStartupMessages(library(omics))

#Build univariate model adm.only~case (2 models: 1st with all covariates, 2nd without covariates)

adm.only <- adm.log[,1:43]

model=lm(adm.only~case+Analytical.batch+gender+Extraction.batch+Gel.status+age.sample,data=adm.log.tc1)
summary(model)


model1=lm(adm.only~case,data=adm.log.tc1)
summary(model1)

anova(model,model1)




adm.log.tc$Analytical.batch=as.factor(adm.log.tc$Analytical.batch)
adm.log.tc$Extraction.batch=as.factor(adm.log.tc$Extraction.batch)

#model<-lmer(adm.only~case+(case|Indiv.ID),adm.log.tc)
#summary(model)


adm.only <- adm.log[,1:43]
str(adm.only)
model2<-mlmer(adm.only~(1|Indiv.ID)+(1|Analytical.batch)+(1|Extraction.batch)+gender+case,var="case", data=adm.log.tc1)
model2$coefficients
plot(model2)

#Univariate Model---------------------------------------------------------------------

#linearmod = function(x){
  mod1 = glm(as.numeric(adm.log.tc1[, "case"]) ~ x, family = binomial())
  summa = summary(mod1)
  return(summa$coefficients[2,4])
}


#Extraction of p-values for all the univariate analyses
pvalues = apply(adm, 2, linearmod)
pval.log = -log(pvalues)/log(10)
plot(pval.log,ylim = c(0,4))

#PHEATMAP
library(pheatmap)
str(adm.only)
adm.only=as.numeric(adm.only)
mycor=cor(adm[,1:43], use="complete.obs")
pheatmap(mycor, cluster_cols = FALSE, cluster_rows = FALSE, breaks = seq(-1,1, length.out = 100), show_rownames = FALSE, 
         show_colnames = FALSE)

















#31 / 1 / 2020
NOTES--------------------------------------------------------------------------------------------------------------------------------------------------------------------------
# Work for next meeting: Univariate models of the form: 1. lm( Adductomics ~ cancer + age + gender ), 2. lm(Adductomics ~ cancer + age + gender + technical confounders)
#                                                       3. ANOVA 2 VS 1, within this we keep the p value, I have some relevant code in liens 139+ for keeping the p value
#                                                        from the model
#                                                        lines 
#                        PCA for every single dataset separately
#                       Check what group penalisation means, we have to enter background knwoledge in a lasso regression, eg. inflammatory
#                        proteins are associated with each other.
#NOTES: Maybe we can add technical confounders as random effects: lmer package. eg. random effect (1 | chip)




#28 / 1/ 2020 : UPDATE

# Let's work on this as reference.

# What I've done is in the headers. Basically, it's imputation, univariate regression with correction for metabolomics.

#24 / 1/ 2020 : UPDATE. 
#This is the code with some stuff for preprocessing.

#We will go thorugh the first Aim (Univariate analyses)

#Rebecca: Protein + Covars----------------------------------------------------------------------------------------------------
library(tidyverse)
library(dplyr)
library(stringr)
library(reshape2)
library(tidyr)
library(devtools)
# package for PCA
library(FactoMineR)
library(factoextra)
library(ggbiplot)
library(ggplot2)
# package for iso forest
library(solitude)
# data preprocessing
# drop rows with na
proteins<-Proteins%>% drop_na()
# create new col "ID"
proteins$Indiv.ID <- row.names(proteins)
#identify individuals with repeated measurement
repeated<-proteins %>%filter(str_detect(Indiv.ID, "_2"))
#manipulate ID string
proteins$Indiv.ID<-str_sub(proteins$Indiv.ID, 1, 7)
#group by ID and take avg for repeated measurement
prot <- proteins %>%
  group_by(Indiv.ID) %>%
  summarize_each(funs(mean))
# check the above code
check<-proteins%>%filter(Indiv.ID==2101850 |Indiv.ID==	2112935)
check_group<-df%>%filter(Indiv.ID==2101850 |Indiv.ID==	2112935)
# cal correlation matrix
cormat <- round(cor(prot),2)
melted_cormat <- melt(cormat)
head(melted_cormat)
#plot correlation matrix
ggplot(data = melted_cormat, aes(x=Var1, y=Var2, fill=value)) + geom_tile()
# get tri of the matrix
get_lower_tri<-function(cormat){
  cormat[upper.tri(cormat)] <- NA
  return(cormat)
}
lower_tri <- get_lower_tri(cormat)
lower_tri
melted_cormat <- melt(lower_tri, na.rm = TRUE)
head(melted_cormat)
#sorted correlation values
df_sorted<- melted_cormat[with(melted_cormat, order(value)), ]

# select important features from Covariates
features<-Covariates%>%select("Indiv.ID","case","age.sample","gender")
# merge covar with proteomics
join<-inner_join(features,prot)
var<-join[,3:96]
class<-join[,2]
# conduct PCA analysis
pca <- prcomp(var,
                 center = TRUE,
                 scale. = TRUE) 
summary(pca)
fviz_eig(pca)
g <- ggbiplot(pca, obs.scale = 1, var.scale = 1, 
              groups = class, ellipse = TRUE, 
              circle = TRUE)
g
fviz_pca_ind(pca,
             col.ind = "cos2", # Color by the quality of representation
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07")
)
fviz_pca_var(pca,
             col.var = "contrib", # Color by contributions to the PC
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
           
)
# Eigenvalues
eig.val <- get_eigenvalue(pca)
eig.val
res.ind <- get_pca_ind(pca)
res.ind$coord          # Coordinates
res.ind$contrib        # Contributions to the PCs
res.ind$cos2           # Quality of representation
# use first PC to identify outliers
# results show around 32 outliers!!!!!
# CHECK with tutors, I am not sure if my approach is correct!!
# Did not find a tutorial on PCA outlier detection
coord<-as.data.frame(res.ind$coord)
dim<-coord[,1]
out<-as.data.frame(dim)
out$ID <- seq.int(nrow(out))
outlier<-out%>%filter(dim>8)
# another outlier detection approach called isolation forest
# results show no outlier for proteomics!!!!!
#score close to 1 means outlier, <0.5 means normal obs
iso <- isolationForest$new()
#proX <- Proteins[, setdiff(colnames(Proteins), "proteins")]
prot_iso<-prot[,-1]
iso$fit(df)
print(iso$scores)
# identify outliers by the distribution of score
quantile(iso$scores$anomaly_score
         , probs = seq(0, 1, length.out = 11))

#Tarana: Adductomics + Covars-------------------------------------------------------------------------------------------------


library(stringr)
work_dir<- "/rds/general/user/tm2119/home/TDS_Session2"

## Adductomics data cleaning
adm<- readRDS('Adductomics/Adductomics_imputed.rds')
adm

dim(adm)

row.adm <- rownames(adm)

row.adm.clean <-gsub("_1$",".1",row.adm)
row.adm.clean
row.adm.clean <-gsub("_2$",".2",row.adm.clean)
row.adm.clean
row.adm.fin <-gsub(".*_","",row.adm.clean)
row.adm.fin
row.adm.fin<-str_sub(row.adm.fin,-20, -3)
head(row.adm.fin)

rownames(adm)<-row.adm.fin
rownames(adm)

#LOG TRANSFORM DATA FOR ADDUCTOMICS
adm.log = log(adm)
head(adm.log)
dim(adm.log)


#Average every two rows
M <- matrix(unlist(c(adm.log)), ncol = 2, byrow = TRUE)
M <- cbind(M, rowMeans(M))
M <- matrix(c(t(M)),ncol = ncol(adm.log), byrow = FALSE)

---------------# add row names and column names 
row.names <- matrix(rownames(adm.log), ncol = 2 ,byrow = TRUE)
rownames(M) <- c(t(cbind(row.names, apply(row.names,1, paste, collapse = "_"))))
colnames(M) <- colnames(adm.log)
rownames(M)
#Create new dataframe only with mean values (an index from row 3 to nrow (number of rows of the table) every 3 rows). 
M.new = M[seq(3, nrow(M), 3), ]

#Since some samples has 2 duplicates(4 in total), hence we are averaging two means and deleting the rest of duplicates
#In total would be 197 samples

rownames(M.new)
M.new.2466652.1<-M.new[157,]
M.new.2466652.2<-M.new[158,]
X2466652<-((M.new.2466652.1)+(M.new.2466652.2))/2
M.new<-rbind(M.new,X2466652)


#Drop the other two
drop.2466652 <-M.new[-c(157),]
M.new<-drop.2466652
drop.2466652.1 <-M.new[-c(158),]
M.new<-drop.2466652.1

dim(M.new)

tail(M.new)

#Do the same for 2224825
rownames(M.new)

M.new.2224825.1<-M.new[32,]
M.new.2224825.2<-M.new[33,]
X2224825<-((M.new.2224825.1)+(M.new.2224825.2))/2

M.new<-rbind(M.new,X2224825)

#Drop the other two
drop.2224825 <-M.new[-c(32),]
M.new<-drop.2224825

drop.2224825.1 <-M.new[-c(33),]
M.new<-drop.2224825.1

dim(M.new)

tail(M.new)

#Rename rows and make
rownames(M.new)[197]<-"2224825_2224825"
rownames(M.new)[197]

rownames(M.new)[196]<-"2466652_2466652"
rownames(M.new)

sort(M.new)

head(M.new)
#Rename all rows. Samples now 197 and all named properly
library(dplyr)
row.M.new<-rownames(M.new)
row.M.new<-substr(row.M.new, start=1, stop=7)
row.M.new

#Create column Indiv.ID that will match the same with covariates
M.new<-cbind(Indiv.ID=row.M.new,M.new)
head(M.new)
rownames(M.new)<-M.new
rownames(M.new)
head(M.new)

#Cleaning for Covariates
covariates <- readRDS('Covariates.rds')
covariates
str(covariates$Indiv.ID)

#Subset only those where Indiv.ID==7 characters
covariates$Indiv.ID=as.character(covariates$Indiv.ID)
covariates = covariates[(which(nchar(covariates$Indiv.ID) == 7)),]
#Group two datasets by Indiv.ID and drop the rest.
covariates$Indiv.ID=as.numeric(covariates$Indiv.ID)
new_covariates<-covariates%>%filter(Indiv.ID>2220020&Indiv.ID<2470519)
new_covariates
dim(new_covariates)
M.new=as.data.frame(M.new)

#Join two datasets(adductomics+covariates) by Indiv.ID
adm.covar <- join(M.new, new_covariates, by = c("Indiv.ID"))
adm.covar
dim(adm.covar)

#UNIVARIATE LINEAR MODELS TO FOLLOW:


#Vasilis: Metabolomics + Covars------------------------------------------------------------------------------------------------

# Metabolome Script

# Load Files, Missingness Investigation----
covar <- readRDS('Covariates.rds')

#Relevelling Gel Status so that NA is a value. OK's are '1', Gel's are '2', NA's are 'Missing'
covar$Gel.status = ifelse(is.na(covar$Gel.status), 'Missing', covar$Gel.status)

mtb = read.csv("/rdsgpfs/general/project/hda_tds/live/Mechanomics/Metabolites/Lung cancer feature table RP NEG_231019.csv")

mtb.by.participant = t(as.matrix(mtb))


#We fix the ID's of participants in mtb and covar datasets so that we can later join the two sets.
library(stringr)

rowmetabol <- rownames(mtb.by.participant)
rowmetabol.clean <- gsub("_1$",".1",rowmetabol)
rowmetabol.clean <- gsub("_2$",".2",rowmetabol.clean)
rowmetabol.fin <- gsub(".*_","",rowmetabol.clean)
rownames(mtb.by.participant) <- rowmetabol.fin

# Excluding 17 blanks in the mtb.by.paricipant dataset
mtb.by.part = mtb.by.participant[18:667,]

names.covariates = sort(as.numeric(rownames(covar)))
names.metabol = sort(as.numeric(rownames(mtb.by.part)))
(names.covariates == names.metabol)
#THere is a discrepancy at position [295]. Namely, there is an extra ID of 2103767 in metabol dataset
names.covariates[295]
names.metabol[295]

#We look further to find the other discrepancy
names.covariates.plus295 = names.covariates[295:648]
names.metabol.plus295 = names.metabol[296:650]
names.covariates.plus295 == names.metabol.plus295

# One More in position 47
names.covariates.plus295[48]
names.metabol.plus295[48]

# The extra ID is 2106943. SO, IN THE MTB dataset, there are 2 MEASUREMENTS for 2 ID's,
# Namely: 2106943, 2103767. We can either take the mean or use mixed models. 

# For these 2 observations, to reduce complexity,
# and since it's only 2/650 observations, we'll take the mean wherever there are 2 observations and
# the observed value where one of them is NA

length(mtb.by.part[rownames(mtb.by.part) == 2106943])
length(mtb.by.part[rownames(mtb.by.part) == 2103767])

vector.2106943 = matrix(as.numeric(mtb.by.part[rownames(mtb.by.part) == 2106943,]), byrow = F, nrow = 2)
vector.2106943[1:2, 120:130]

vec1 = as.data.frame(vector.2106943)
vec1.3 = ifelse(is.na(vec1[1,1:4828]) | is.na(vec1[2,1:4828]), 1,0 )
vec.all = rbind(vec1, vec1.3)
vec.all[is.na(vec.all)] <- 0

# Probably not the fastest way but still works. Wherever there is 1 NA, we take the value. WHerevere both
# observations are available, we take the mean. NA's are changed to 0's for facilitating code

mean.or.NA = ifelse(vec.all[3,] == 0, (vec.all[1,] + vec.all[2,])/2, vec.all[,1] +  vec.all[2,])
meanNA2106943 = unlist(mean.or.NA)
meanNA2106943[meanNA2106943 == 0] <- NA
mtb.by.part2 = rbind(mtb.by.part, meanNA2106943)

#Dropping the other rows
drop.index.2106943 = which(rownames(mtb.by.part2) == "2106943")
mtb.by.part2 = mtb.by.part2[-drop.index.2106943,]
dim(mtb.by.part2)

# The same process for ID 2103767. rownames(mtb.by.part2) lathos
vector.2103767 = matrix(as.numeric(mtb.by.part2[rownames(mtb.by.part2) == 2103767,]), byrow = F, nrow = 2)
vector.2103767[1:2, 120:130]

vec1 = as.data.frame(vector.2103767)
vec1.3 = ifelse(is.na(vec1[1,1:4828]) | is.na(vec1[2,1:4828]), 1,0 )
vec.all = rbind(vec1, vec1.3)
vec.all[is.na(vec.all)] <- 0

# Probably not the fastest way but still works. Wherever there is 1 NA, we take the value. WHerevere both
# observations are available, we take the mean. NA's are changed to 0's for facilitating code

mean.or.NA = ifelse(vec.all[3,] == 0, (vec.all[1,] + vec.all[2,])/2, vec.all[,1] +  vec.all[2,])
meanNA2103767 = unlist(mean.or.NA)
meanNA2103767[meanNA2103767 == 0] <- NA
mtb.by.part3 = rbind(mtb.by.part2, meanNA2103767)

#Dropping the other rows
drop.index.2103767 = which(rownames(mtb.by.part3) == "2103767")
mtb.by.part3 = mtb.by.part3[-drop.index.2103767,]
dim(mtb.by.part3)

#648, now they match with covars

# Firstly, we will be excluding those metabolites for whom >70% of the values are missing
mtb.NAs = ifelse(is.na(mtb.by.part3) == T, 1, 0)

na.proportion.vector = apply(mtb.NAs, 1, mean)

hist(na.proportion.vector,breaks = 1000)
# DATA-DRIVEN choice of cut-off: 0.65

mtb.lessthan60 = mtb.by.part3[which(na.proportion.vector < 0.6),]
dim(mtb.lessthan65)
  
# In the remaining dataset, we will be treating missing or not as a binary outcome 
# 
# and run logistic regression as follows: missingness ~ age + gender + BMI + ...
#
# We will accordingly correct for multiple comparisons
linearmod.NAs = function(metabolite.missing){
  mod1 = glm(metabolite.missing ~ covar$age.sample + covar$case + covar$cohort ,
             family = binomial())
  summa = summary(mod1)
  age.pval = summa$coefficients[2,4]
  ccstatus.pval = summa$coefficients[3,4]
  cohort.pval = summa$coefficients[4,4]
  df.pval = data.frame(summa$coefficients[2,4], summa$coefficients[3,4], summa$coefficients[4,4])
  colnames(df.pval) = NULL
  return(df.pval)
  
}

pval = apply(mtb.NAs, 2, linearmod.NAs)
pvalues = matrix(unlist(pval), nrow = ncol(mtb.NAs), ncol = 3,byrow = T)
apply(pvalues, 2, function(x){min(p.adjust(x, method = 'BH'))})

# Imputation----
# Strategy: "QRILC, a missing data imputation method that performs the imputation
# of left-censored missing data using random draws from a truncated distribution with parameters
# estimated using quantile regression"
install.packages("BiocManager")
library(BiocManager)
BiocManager::install("pcaMethods")
library(pcaMethods)
BiocManager::install("impute")
library(impute)

install.packages('imputeLCMD')
library(imputeLCMD)

#We ASSUME that the data is NOT log-transformed

mtb.numeric = matrix(as.numeric(mtb.by.part3), nrow(mtb.by.part3))

num.mat.1 = mtb.numeric
num.mat.ln = log(num.mat.1)

imp.mtb = impute.QRILC(mtb.numeric)
# Errors produced, "In qnorm((pNAs + 0.001), mean = mean.CDD, sd = sd.CDD) : NaNs produced"
#
# We get the source code and try to see what's going on. 

#The issue was that nFeatures and nSamples were switched

tune.sigma = 1
nFeatures = dim(num.mat)[2]
nSamples = dim(num.mat)[1]
dataSet.imputed = num.mat
QR.obj = list()
for (i in 1:(nSamples)) {
  curr.sample = num.mat.ln[i, ]
  pNAs = length(which(is.na(curr.sample)))/length(curr.sample)
  upper.q = 0.99
  q.normal = qnorm(seq((pNAs + 0.001), (upper.q + 0.001),(upper.q - pNAs)/(upper.q * 100)), mean = 0, sd = 1)
  q.curr.sample = quantile(curr.sample, probs = seq(0.001, 
                                                    (upper.q + 0.001), 0.01), na.rm = T)
  temp.QR = lm(q.curr.sample ~ q.normal)
  QR.obj[[i]] = temp.QR
  mean.CDD = temp.QR$coefficients[1]
  sd.CDD = as.numeric(temp.QR$coefficients[2])
  data.to.imp = rtmvnorm(n = nFeatures, mean = mean.CDD, 
                         sigma = sd.CDD * tune.sigma, upper = qnorm((pNAs+0.001), mean = mean.CDD, sd = sd.CDD), algorithm = c("gibbs"))
  curr.sample.imputed = curr.sample
  curr.sample.imputed[which(is.na(curr.sample))] = data.to.imp[which(is.na(curr.sample))]
  dataSet.imputed[i, ] = curr.sample.imputed
}

num.mat.imputed = dataSet.imputed

# Visual inspection of histograms suggests that undetected values
# have been imputed at low ranges. 
hist(num.mat.imputed[,48],breaks = 100)
hist(num.mat[,48],breaks = 100)

#We backtransform to linear scale
metabolites.imp = exp(num.mat.imputed)
range(as.numeric(mtb.by.part3[,26]),na.rm = T)


# Univariate Regression with significance corrections ----
metabolites.imp

# Treating lung cancer cases as the binary outcome, we code a function (linearmod) that sequentially checks
# every metabolite for significance

linearmod = function(x.indep){
  mod1 = glm(as.numeric(covar[, "case"]) ~ x.indep, family = binomial())
  summa = summary(mod1)
  return(summa$coefficients[2,4])
}

#Extraction of p-values for all the univariate analyses
#of cancer ~ metabolite1, cancer ~ metabolite2 etc.

pvalues = apply(metabolites.imp, 2, linearmod)
pval.log = -log(pvalues)/log(10)
plot(pval.log,ylim = c(0,4))

#Bonferroni correction
bonferroni.cutoff = 0.05/ncol(metabolites.imp)
plot.bonf = -log(bonferroni.cutoff)
abline(h=plot.bonf, col = 'red')

#Benjamini-Hochberg Procedure
pval.BH = p.adjust(pvalues, method = "BH") # None significant at 0.05

sum(pval.BH < 0.05) # NONE !!!!
range(pval.BH) # W O W. Range of BH-corrected pvals is 0.9896816 0.9997920

#Let's try adjusting for Smoking Status
linearmod.adj.for.Smoking = function(x.indep){
  mod1 = glm(as.numeric(covar[, "case"]) ~ x.indep + covar$smoking_status, family = binomial())
  summa = summary(mod1)
  return(summa$coefficients[2,4])
}

#Again, pvalue extraction
pvalues = apply(metabolites.imp, 2, linearmod.adj.for.Smoking)
pval.log = -log(pvalues)/log(10)
plot(pval.log,ylim = c(0,4))

#Bonferroni correction
bonferroni.cutoff = 0.05/ncol(metabolites.imp)
plot.bonf = -log(bonferroni.cutoff)
abline(h=plot.bonf, col = 'red')

#Benjamini-Hochberg Procedure
pval.BH = p.adjust(pvalues, method = "BH") # None significant at 0.05

sum(pval.BH < 0.05) # NONE AGAIN !!!!
range(pval.BH) # Range of BH-corrected pvals is now 0.9529 0.9997920

#Let's try adjusting for Smoking Duration AND age 
linearmod.adj.for.Smoking = function(x.indep){
  mod1 = glm(as.numeric(covar[, "case"]) ~ x.indep + covar$packyears + covar$Monocytes + covar$bmi + covar$B+covar$Gel.status, family = binomial())
  summa = summary(mod1)
  return(summa$coefficients[2,4])
}

#Again, pvalue extraction
pvalues = apply(metabolites.imp, 2, linearmod.adj.for.Smoking)
pval.log = -log(pvalues)/log(10)
plot(pval.log,ylim = c(0,4))

#Bonferroni correction
bonferroni.cutoff = 0.05/ncol(metabolites.imp)
plot.bonf = -log(bonferroni.cutoff)
abline(h=plot.bonf, col = 'red')

#Benjamini-Hochberg Procedure
pval.BH = p.adjust(pvalues, method = "BH") # None significant at 0.05

sum(pval.BH < 0.05) # NONE AGAIN !!!!

range(pval.BH) # Range of BH-corrected pvals is now â†“ 0.86855 0.9997920






# Multivariate Approaches ----

# 1. PCA
mtb.pca = prcomp(metabolites.imp, center = T, scale. = T)

pca.numeric = unlist(mtb.pca[1])
sum(pca.numeric[1:220]) / sum(pca.numeric)


mtb.pca$rotation

# PLS model

devtools::install_github("mixOmicsTeam/mixOmics")
suppressPackageStartupMessages(library(mixOmics))
suppressPackageStartupMessages(library(sgPLS))
library(lme4)
library(sgPLS)
library(utils)
library(pheatmap)
library(RColorBrewer)
source("Scripts/pls_functions.R")
MyPLSDA_pooled <- plsda(X, case, ncomp = 1,
                        mode = "regression")
MyPLSDA_pooled$loadings$X
MysPLSDA_pooled <- splsda(X, case, ncomp=1, mode="regression", keepX=6)

MysPLSDA_pooled$loadings$X
MysPLSDA_pooled$loadings$X[MysPLSDA_pooled$loadings$X!=0,]

set.seed(1)
res_splsda=CalibratesPLSDA(dataX=X, dataY=case, ncomp=1, Nrepeat=5)
PlotCalib(res=res_splsda)

